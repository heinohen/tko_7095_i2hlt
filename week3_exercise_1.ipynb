{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ff9a915539c44a1bd5259ce7c5d65ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cec6ef4762c4cf7a9cab5e73368e03e",
              "IPY_MODEL_71ffa19f8e3c4c73848941ad27436a7d",
              "IPY_MODEL_521aa790c6474d9b95fa16922a582751"
            ],
            "layout": "IPY_MODEL_9dc92e72872242d98d645676a20983e7"
          }
        },
        "1cec6ef4762c4cf7a9cab5e73368e03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fe91e3ff76a49208de40be21f0ac909",
            "placeholder": "​",
            "style": "IPY_MODEL_d4d745e26efc477198c5b2d3b0b1ab13",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "71ffa19f8e3c4c73848941ad27436a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553e11fb700f41a3add5590ab70a5cfb",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca7ab1f301bc4c749b4ddd6fc2fcd7cc",
            "value": 25000
          }
        },
        "521aa790c6474d9b95fa16922a582751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926925da7b6c4a03b37529d4daa3468a",
            "placeholder": "​",
            "style": "IPY_MODEL_c75756456c82483c982ff048a115134c",
            "value": " 25000/25000 [00:25&lt;00:00, 964.81 examples/s]"
          }
        },
        "9dc92e72872242d98d645676a20983e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe91e3ff76a49208de40be21f0ac909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d745e26efc477198c5b2d3b0b1ab13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553e11fb700f41a3add5590ab70a5cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7ab1f301bc4c749b4ddd6fc2fcd7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "926925da7b6c4a03b37529d4daa3468a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75756456c82483c982ff048a115134c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de56856838764bb0be745962af356337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb081bcf0f6147bbaf7bc81a4d25d37b",
              "IPY_MODEL_f33a795aa23f40a8a60cd7daa8d9934e",
              "IPY_MODEL_bba0ab1518104b50a3f1ece539de3712"
            ],
            "layout": "IPY_MODEL_e56cfd61776e4c90b8fce66567a2088f"
          }
        },
        "cb081bcf0f6147bbaf7bc81a4d25d37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc52a3de92e74df297405c0266b69bdc",
            "placeholder": "​",
            "style": "IPY_MODEL_47a5cb83f673461eb863044df9b0035f",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "f33a795aa23f40a8a60cd7daa8d9934e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_028dd62ca4834879b14c35c9866e999f",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a349d28c462d44c7978ca09989d1bb7b",
            "value": 25000
          }
        },
        "bba0ab1518104b50a3f1ece539de3712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a81fd7965a481a98036ab78e4ea095",
            "placeholder": "​",
            "style": "IPY_MODEL_e380839d70b14a9aa942a800cce7c605",
            "value": " 25000/25000 [00:22&lt;00:00, 849.87 examples/s]"
          }
        },
        "e56cfd61776e4c90b8fce66567a2088f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc52a3de92e74df297405c0266b69bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a5cb83f673461eb863044df9b0035f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "028dd62ca4834879b14c35c9866e999f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a349d28c462d44c7978ca09989d1bb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92a81fd7965a481a98036ab78e4ea095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e380839d70b14a9aa942a800cce7c605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heinohen/tko_7095_i2hlt/blob/main/week3_exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Before we start running our own Python code, install the required Python packages using [pip](https://en.wikipedia.org/wiki/Pip):\n",
        "\n",
        "* [`transformers`](https://huggingface.co/docs/transformers/index) is a popular deep learning package primarily on top of torch, we need to reinstall it with the [torch] configuration (might take a substantial amount of time)\n",
        "* [`datasets`](https://huggingface.co/docs/datasets/) provides support for loading, creating, and manipulating datasets\n",
        "* evaluate is a library of performance metrics (like accuracy etc)\n",
        "\n",
        "**You will likely need to do a Runtime/Restart session for everything to work after the installation.**"
      ],
      "metadata": {
        "id": "LDZZUKzfPRWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q datasets evaluate\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "fKPHBYptQDsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cfc37e-d931-484b-eaa9-2b1b900ccde6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Above, the `!` at the start of the line tells the notebook to run the line as an operating system command rather than Python code, and the `-q` argument to `pip` runs the command in \"quiet\" mode, with less output.)"
      ],
      "metadata": {
        "id": "xOeI-LA9RcYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Get and prepare data\n",
        "\n",
        "*   Let us work with the IMDB dataset of movie review sentiment\n",
        "*   25,000 positive reviews\n",
        "*   25,000 negative reviews\n",
        "*   50,000 unlabeled reviews (which we discard for the time being)\n"
      ],
      "metadata": {
        "id": "_fCdfQfNNzwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint #pprint => pretty-print, I use it occassionally throughout the notebook\n",
        "from google.colab import userdata\n",
        "userdata.get('hf')\n",
        "import datasets\n",
        "import torch\n",
        "dset=datasets.load_dataset(\"imdb\")\n",
        "pprint(dset)"
      ],
      "metadata": {
        "id": "QxmgHoKDTN2_",
        "outputId": "0a1210b3-f7fb-4c7e-87c0-24fa419d8a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dset=dset.shuffle() #This is never a bad idea, datasets may have ordering to them, which is not what we want\n",
        "del dset[\"unsupervised\"] #Delete the unlabeled part of the dataset, we don't need it for anything"
      ],
      "metadata": {
        "id": "lbmgiOj4pWw-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(dset['train'][42]['text'])\n",
        "print(dset['train'][42]['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI3kyD3vry8C",
        "outputId": "002674f1-7455-4b84-a018-c2d72b50e8bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Imagine a woman alone in a house for forty five minutes in which absolutely '\n",
            " 'nothing happens. Then this goes on twice more. The writing is flat and '\n",
            " 'lifeless, and jokes unfunny, and the bad acting keeps you from caring about '\n",
            " 'any of the characters, even when they battle wolf packs and get beaten up by '\n",
            " 'fraternity goons. Anyone that ranked this movie higher than a two is not '\n",
            " 'fully sane.')\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize and map vocabulary\n",
        "         \n",
        "*   We need to achieve two complementary tasks\n",
        "*   **Tokenize** split the text into units which can be interpreted as features (words in this case)\n",
        "*   **Map vocabulary** build the feature vector for each example\n",
        "*   Since this is NLP, here it means listing the non-zero elements of the feature vector, or in other words the indices of the vocabulary items\n",
        "* Since we work with the bag of words (BoW) representation, these do not need to be (and are not) in the order in which they appear in the text\n",
        "* These indices then refer to the rows in the embedding matrix\n",
        "*   A traditional and well-tested way it to use sklearn's feature extraction package\n",
        "*   CountVectorizer is most likely what we want in here, because we only want the ids, nothing else\n",
        "* But for other NLP work the TfidfVectorizer is also very handy\n",
        "\n"
      ],
      "metadata": {
        "id": "KMnqQ78cMpk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.feature_extraction\n",
        "\n",
        "# max_features means the size of the vocabulary\n",
        "# which means max_features most-common words\n",
        "vectorizer=sklearn.feature_extraction.text.CountVectorizer(binary=True,max_features=20000)\n",
        "\n",
        "texts=[ex[\"text\"] for ex in dset[\"train\"]] #get a list of all texts from the training data\n",
        "vectorizer.fit(texts) #\"Trains\" the vectorizer, i.e. builds its vocabulary\n"
      ],
      "metadata": {
        "id": "MYOtKJu7Mohd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "2e79731f-7305-42df-e44a-659fe9234378"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(binary=True, max_features=20000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(binary=True, max_features=20000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True, max_features=20000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the feature vectors\n",
        "\n",
        "* This is super-easy with the vectorizer\n",
        "* It produces a sparse matrix of the non-zero elements"
      ],
      "metadata": {
        "id": "UDNy3w8reO6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_example(ex):\n",
        "    vectorized=vectorizer.transform([ex[\"text\"]]) # [...] because the vectorizer expects a list/iterable over inputs, not one input\n",
        "    non_zero_features=vectorized.nonzero()[1] #.nonzero gives a pair of (rows,columns), we want the columns\n",
        "    non_zero_features+=1 #feature index 0 will have a special meaning\n",
        "                         # so let us not produce it by adding +1 to everything\n",
        "    return {\"input_ids\":non_zero_features}\n",
        "\n",
        "vectorized=vectorize_example(dset[\"train\"][0])"
      ],
      "metadata": {
        "id": "5H9AQOc2rGIO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorized)"
      ],
      "metadata": {
        "id": "ECqsgmwTXaOC",
        "outputId": "11f08c3e-635d-49ee-9698-2552b8c4361c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': array([  423,   424,   433,   793,   891,  1494,  1516,  1703,  1733,\n",
            "        1757,  2161,  2302,  2453,  2584,  2612,  2633,  2697,  3239,\n",
            "        3340,  3629,  3638,  4484,  4629,  4967,  5071,  5401,  5882,\n",
            "        5938,  6051,  6205,  6304,  6316,  6320,  6375,  6649,  6668,\n",
            "        6774,  6894,  7139,  7671,  7783,  8117,  8278,  8311,  8339,\n",
            "        8427,  8443,  8474,  8557,  8770,  9084,  9595,  9621,  9630,\n",
            "        9875, 10105, 10122, 10453, 10481, 10496, 10626, 11164, 11459,\n",
            "       11592, 11657, 11844, 11980, 12121, 12222, 12348, 12421, 12423,\n",
            "       12451, 12492, 12721, 13125, 13127, 13268, 13305, 14061, 14079,\n",
            "       14273, 14343, 15122, 15323, 15678, 15885, 15922, 16023, 16163,\n",
            "       16471, 16922, 17076, 17421, 17431, 17624, 17710, 17879, 17891,\n",
            "       17949, 17961, 18112, 18167, 18459, 19049, 19438, 19507, 19519,\n",
            "       19548, 19711, 19744, 19747, 19798, 19803], dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can map back to vocabulary and check that everything works\n",
        "# vectorizer.vocabulary_ is a dictionary {key:word, value:idx}\n",
        "\n",
        "idx2word=dict((i,w) for (w,i) in vectorizer.vocabulary_.items()) #inverse the vocab dictionary\n",
        "words=[]\n",
        "for idx in vectorized[\"input_ids\"]:\n",
        "    words.append(idx2word[idx-1]) ## It is easy to forgot we moved all by +1\n",
        "pprint(\", \".join(words)) #This is now the bag of words representation of the document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvgd3IrWfCai",
        "outputId": "5400f68d-304b-47e8-9a21-b94fc604afb8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('acting, action, actor, always, and, back, bad, be, beautiful, been, bold, '\n",
            " 'brad, brooke, burrows, but, by, camera, chosen, classic, comment, comments, '\n",
            " 'cute, days, desperately, diane, doesn, either, elizabeth, end, eric, evans, '\n",
            " 'ever, every, except, fan, far, feels, films, for, girl, good, had, has, '\n",
            " 'have, he, helen, help, here, him, how, in, is, it, itself, just, kruger, '\n",
            " 'lab, like, linda, lingers, looks, me, miscast, money, more, my, need, no, '\n",
            " 'now, of, on, one, opera, or, paid, peter, peterson, pitt, plastic, puts, '\n",
            " 'quality, rather, really, role, saffron, see, shame, she, should, since, '\n",
            " 'soap, start, story, sure, surgery, takes, taylor, than, the, thinking, this, '\n",
            " 'to, toole, troy, ve, way, well, were, when, with, won, wonderful, worst, '\n",
            " 'would')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing / vectorizing the whole dataset\n",
        "\n",
        "* The datasets library allows us to efficiently map() a function across the whole dataset\n",
        "* Can run in parallel\n",
        "\n",
        "**Note**: confusingly, and unlike the Python`map` function, [`Dataset.map`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map) function _updates_ its argument dataset, keeping existing values. Here, the call adds the values returned by the function call (here `input_ids`) to each example while also keeping the original `text` and `label` values.\n"
      ],
      "metadata": {
        "id": "i33KIMgkiIn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the tokenizer to the whole dataset using .map()\n",
        "dset_tokenized = dset.map(vectorize_example,num_proc=4)\n",
        "pprint(dset_tokenized[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2ff9a915539c44a1bd5259ce7c5d65ba",
            "1cec6ef4762c4cf7a9cab5e73368e03e",
            "71ffa19f8e3c4c73848941ad27436a7d",
            "521aa790c6474d9b95fa16922a582751",
            "9dc92e72872242d98d645676a20983e7",
            "7fe91e3ff76a49208de40be21f0ac909",
            "d4d745e26efc477198c5b2d3b0b1ab13",
            "553e11fb700f41a3add5590ab70a5cfb",
            "ca7ab1f301bc4c749b4ddd6fc2fcd7cc",
            "926925da7b6c4a03b37529d4daa3468a",
            "c75756456c82483c982ff048a115134c",
            "de56856838764bb0be745962af356337",
            "cb081bcf0f6147bbaf7bc81a4d25d37b",
            "f33a795aa23f40a8a60cd7daa8d9934e",
            "bba0ab1518104b50a3f1ece539de3712",
            "e56cfd61776e4c90b8fce66567a2088f",
            "bc52a3de92e74df297405c0266b69bdc",
            "47a5cb83f673461eb863044df9b0035f",
            "028dd62ca4834879b14c35c9866e999f",
            "a349d28c462d44c7978ca09989d1bb7b",
            "92a81fd7965a481a98036ab78e4ea095",
            "e380839d70b14a9aa942a800cce7c605"
          ]
        },
        "id": "33xMYRd0q2B9",
        "outputId": "81cc4c56-8f4a-4097-ef46-ed3d82416c29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ff9a915539c44a1bd5259ce7c5d65ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de56856838764bb0be745962af356337"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [423,\n",
            "               424,\n",
            "               433,\n",
            "               793,\n",
            "               891,\n",
            "               1494,\n",
            "               1516,\n",
            "               1703,\n",
            "               1733,\n",
            "               1757,\n",
            "               2161,\n",
            "               2302,\n",
            "               2453,\n",
            "               2584,\n",
            "               2612,\n",
            "               2633,\n",
            "               2697,\n",
            "               3239,\n",
            "               3340,\n",
            "               3629,\n",
            "               3638,\n",
            "               4484,\n",
            "               4629,\n",
            "               4967,\n",
            "               5071,\n",
            "               5401,\n",
            "               5882,\n",
            "               5938,\n",
            "               6051,\n",
            "               6205,\n",
            "               6304,\n",
            "               6316,\n",
            "               6320,\n",
            "               6375,\n",
            "               6649,\n",
            "               6668,\n",
            "               6774,\n",
            "               6894,\n",
            "               7139,\n",
            "               7671,\n",
            "               7783,\n",
            "               8117,\n",
            "               8278,\n",
            "               8311,\n",
            "               8339,\n",
            "               8427,\n",
            "               8443,\n",
            "               8474,\n",
            "               8557,\n",
            "               8770,\n",
            "               9084,\n",
            "               9595,\n",
            "               9621,\n",
            "               9630,\n",
            "               9875,\n",
            "               10105,\n",
            "               10122,\n",
            "               10453,\n",
            "               10481,\n",
            "               10496,\n",
            "               10626,\n",
            "               11164,\n",
            "               11459,\n",
            "               11592,\n",
            "               11657,\n",
            "               11844,\n",
            "               11980,\n",
            "               12121,\n",
            "               12222,\n",
            "               12348,\n",
            "               12421,\n",
            "               12423,\n",
            "               12451,\n",
            "               12492,\n",
            "               12721,\n",
            "               13125,\n",
            "               13127,\n",
            "               13268,\n",
            "               13305,\n",
            "               14061,\n",
            "               14079,\n",
            "               14273,\n",
            "               14343,\n",
            "               15122,\n",
            "               15323,\n",
            "               15678,\n",
            "               15885,\n",
            "               15922,\n",
            "               16023,\n",
            "               16163,\n",
            "               16471,\n",
            "               16922,\n",
            "               17076,\n",
            "               17421,\n",
            "               17431,\n",
            "               17624,\n",
            "               17710,\n",
            "               17879,\n",
            "               17891,\n",
            "               17949,\n",
            "               17961,\n",
            "               18112,\n",
            "               18167,\n",
            "               18459,\n",
            "               19049,\n",
            "               19438,\n",
            "               19507,\n",
            "               19519,\n",
            "               19548,\n",
            "               19711,\n",
            "               19744,\n",
            "               19747,\n",
            "               19798,\n",
            "               19803],\n",
            " 'label': 0,\n",
            " 'text': \"Well, were to start? This is by far one of the worst films I've ever \"\n",
            "         \"paid good money to see. I won't comment on the story itself, it's a \"\n",
            "         'wonderful classic, but here it feels like a soap opera. To start '\n",
            "         \"with, the acting, except for Eric Bana, is soap opera quality. I've \"\n",
            "         'always been a fan of Brad Pitt, but here every actor on The Bold and '\n",
            "         \"the Beautiful puts him to shame. The camera action doesn't help, \"\n",
            "         \"either. How it lingers on him when he's thinking, it just takes me \"\n",
            "         \"back to Brooke Forrester's days in the lab! Peter O'Toole has either \"\n",
            "         'had a really bad plastic surgery, or he is desperately in need of '\n",
            "         'one. Either way, he looks more like Linda Evans than Linda Evans! '\n",
            "         'And to end my comments, Diane Kruger is a cute girl, but she sure is '\n",
            "         'no Helen of Troy. Peterson should rather have chosen Saffron Burrows '\n",
            "         'for the role, since Elizabeth Taylor would be rather miscast by now.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input encoding for MLP\n",
        "\n",
        "* Our `input_ids` are an array containing the indices of the tokens found in the text\n",
        "* This corresponds to the indices into the row of the embedding matrix in the model\n",
        "* That seems to be exactly what we need!\n"
      ],
      "metadata": {
        "id": "XTtyHQpIIJWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batching and padding\n",
        "\n",
        "* When working with neural networks, one rarely trains one example at a time\n",
        "* Instead, processing always happens a batch at a time\n",
        "* This has two important reasons:\n",
        "  1. No batching is too slow (GPU parallelization cannot kick in across examples)\n",
        "  2. The gradients are averaged across the whole batch and applied only once, i.e. batching acts as a regularizer and improves the stability of the training\n"
      ],
      "metadata": {
        "id": "JvaP1DpHjI3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding and Collation (forming a batch)\n",
        "\n",
        "## Padding:\n",
        "\n",
        "* In order to build a batch as a 2D array of (example, seq), we need to fit together examples of different length\n",
        "* Solution: pad the shorter examples with zeroes to the length of the longest example in the batch\n",
        "* Make sure that zero is understood as padding value rather than a (hypothetical) feature with index 0\n",
        "* This is best shown by example, it is in the end easier than it may sound\n",
        "\n",
        "## Collation:\n",
        "\n",
        "* Much like examples are dictionaries with the data, also batches are dictionaries with the data\n",
        "* The only difference is that in a batch, all data tensors have one extra dimension, that's all there is to it\n",
        "\n",
        "## Collator function:\n",
        "\n",
        "* Padding and collation is taken care of by a single function in the HF libraries\n",
        "* It receives a list of examples, and returns a ready batch\n",
        "* The surrounding library code takes care of forming these lists\n",
        "* Let's try to implement one below"
      ],
      "metadata": {
        "id": "hNYxw92nj51B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) I need to define it here, will explain below\n",
        "# 2) I show here a very straightforward implementation of padding and collation\n",
        "# 3) Normally, one would use transformers.DataCollatorWithPadding but that assumes\n",
        "#    a particular tokenizer, to which it outsources much of the work, and we do not\n",
        "#    have it\n",
        "def collator(list_of_examples):\n",
        "    #this is easy, labels are made into a single tensor\n",
        "    batch={\"labels\":torch.tensor(list(ex[\"label\"] for ex in list_of_examples))}\n",
        "    #the worse bit is now to pad the examples, as they are of different length\n",
        "    tensors=[]\n",
        "    max_len=max(len(example[\"input_ids\"]) for example in list_of_examples) #this is the longest example in the batch\n",
        "    #everything needs to be padded to fit in length the longest example\n",
        "    #(so we can build a single tensor out of it)\n",
        "    for example in list_of_examples:\n",
        "        ids=torch.tensor(example[\"input_ids\"]) #pick the input ids\n",
        "        # pad(what,(from_left, from_right)) <- this is how we call the stock pad function\n",
        "        padded=torch.nn.functional.pad(ids,(0,max_len-ids.shape[0])) #pad by max - current length, pads with zero by default\n",
        "        tensors.append(padded) #accumulated the padded ids\n",
        "    batch[\"input_ids\"]=torch.vstack(tensors) #now that we have all of them the same length, a simple vstack() stacks them up\n",
        "    return batch #...and that's all there is to it\n",
        "\n",
        "\n",
        "\n",
        "#Build a batch from 2 examples, with padding\n",
        "batch=collator([dset_tokenized[\"train\"][2],dset_tokenized[\"train\"][7]])\n",
        "print(\"Shape of labels:\",batch[\"labels\"].shape)\n",
        "print(\"Shape of input_ids:\",batch[\"input_ids\"].shape)\n",
        "pprint(batch[\"labels\"])\n",
        "pprint(batch[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXXDxNo6kwfA",
        "outputId": "4c77002d-04e8-40b0-ce64-80bf7befe551"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of labels: torch.Size([2])\n",
            "Shape of input_ids: torch.Size([2, 182])\n",
            "tensor([0, 0])\n",
            "tensor([[  307,   386,   454,   598,   609,   775,   860,   863,   891,  1004,\n",
            "          1048,  1117,  1209,  1302,  1314,  1371,  1516,  1522,  1703,  1738,\n",
            "          1795,  1879,  1883,  1888,  1927,  1988,  2207,  2264,  2300,  2612,\n",
            "          2633,  2717,  3183,  3848,  4066,  4145,  4209,  4252,  4722,  4932,\n",
            "          4973,  5091,  5436,  5543,  5772,  6027,  6325,  6589,  6608,  6677,\n",
            "          6678,  6851,  6852,  6884,  6891,  6894,  6911,  6915,  6948,  7005,\n",
            "          7111,  7132,  7139,  7334,  7380,  7391,  7682,  7968,  8117,  8278,\n",
            "          8311,  8339,  8730,  8770,  8921,  9059,  9084,  9092,  9274,  9315,\n",
            "          9485,  9595,  9619,  9621,  9648,  9708,  9875,  9966, 10068, 10136,\n",
            "         10138, 10177, 10207, 10224, 10226, 10536, 10624, 10665, 10874, 10958,\n",
            "         11012, 11178, 11200, 11443, 11494, 11623, 11746, 11763, 11819, 12086,\n",
            "         12121, 12188, 12192, 12278, 12348, 12382, 12394, 12421, 12492, 12554,\n",
            "         12567, 12698, 13051, 13209, 13368, 13388, 13505, 13506, 13519, 14103,\n",
            "         14273, 14304, 14621, 14784, 15197, 15261, 15359, 15445, 15480, 15486,\n",
            "         15691, 15692, 15922, 16118, 16212, 16355, 16469, 16533, 16700, 17040,\n",
            "         17313, 17365, 17797, 17879, 17887, 17891, 17904, 17911, 17923, 17938,\n",
            "         17946, 17949, 18066, 18073, 18112, 18163, 18654, 18803, 18962, 18967,\n",
            "         19112, 19363, 19444, 19538, 19558, 19601, 19639, 19665, 19711, 19798,\n",
            "         19847, 19977],\n",
            "        [  157,   307,   345,   424,   731,   795,   863,   891,  1117,  1156,\n",
            "          1204,  1209,  1389,  1703,  1738,  1809,  2204,  2236,  2300,  2612,\n",
            "          2989,  3145,  3614,  4138,  5649,  5852,  6307,  7028,  7224,  7998,\n",
            "          8230,  8311,  8582,  8629,  8636,  8673,  8797,  9128,  9595,  9621,\n",
            "          9737,  9886,  9999, 10001, 10080, 10399, 10416, 10427, 11026, 11123,\n",
            "         11265, 11746, 12047, 12106, 12121, 12241, 12348, 12349, 12398, 12423,\n",
            "         12554, 12618, 12702, 12709, 13351, 13565, 14079, 14304, 15430, 15431,\n",
            "         15439, 15927, 16469, 16512, 16663, 17076, 17377, 17468, 17620, 17627,\n",
            "         17887, 17891, 17901, 17904, 17938, 17944, 17961, 18112, 18339, 18524,\n",
            "         18885, 19107, 19295, 19396, 19418, 19593, 19711, 19783, 19803, 19897,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the MLP model\n",
        "\n",
        "* Now that all of our data is in shape, we can build the model\n",
        "* That is luckily quite easy in this case\n",
        "\n",
        "The model class in its simplest form has `__init__()` which instantiates the layers and `forward()` which implements the actual computation. For more information on these, please see the [PyTorch turorial](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)."
      ],
      "metadata": {
        "id": "AOYYF5I1OWG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "# A model wants a config, I can simply inherit from the base\n",
        "# class for pretrained configs\n",
        "class MLPConfig(transformers.PretrainedConfig):\n",
        "    pass\n",
        "\n",
        "# This is the model\n",
        "class MLP(transformers.PreTrainedModel):\n",
        "\n",
        "    config_class=MLPConfig\n",
        "\n",
        "    # In the initialization method, one instantiates the layers\n",
        "    # these will be, for the most part the trained parameters of the model\n",
        "    def __init__(self,config):\n",
        "        super().__init__(config)\n",
        "        self.vocab_size=config.vocab_size #embedding matrix row count\n",
        "        # Build and initialize embedding of vocab size +1 x hidden size (+1 because of the padding index 0!)\n",
        "        self.embedding=torch.nn.Embedding(num_embeddings=self.vocab_size+1,embedding_dim=config.hidden_size,padding_idx=0)\n",
        "        # Normally you would not initialize these yourself, but I have my reasons here ;)\n",
        "        torch.nn.init.uniform_(self.embedding.weight.data,-0.001,0.001) #initialize the embeddings with small random values\n",
        "        # Note! This function is relatively clever and keeps the embedding for 0, the padding, pure zeros\n",
        "        # This takes care of the lower half of the network, now the upper half\n",
        "        # Output layer: hidden size x output size\n",
        "        self.output=torch.nn.Linear(in_features=config.hidden_size,out_features=config.nlabels)\n",
        "        # Now we have the parameters of the model\n",
        "\n",
        "\n",
        "    # The computation of the model is put into the forward() function\n",
        "    # it receives a batch of data and optionally the correct `labels`\n",
        "    #\n",
        "    # If given `labels` it returns (loss,output)\n",
        "    # if not, then it returns (output,)\n",
        "    def forward(self,input_ids,labels=None):\n",
        "        #1) sum up the embeddings of the items\n",
        "        embedded=self.embedding(input_ids) #(batch,ids)->(batch,ids,embedding_dim)\n",
        "        # Since the Embedding keeps the first row of the matrix pure zeros, we don't need to worry about the padding\n",
        "        # so next we sum the embeddings across the word dimension\n",
        "        # (batch,ids,embedding_dim) -> (batch,embedding_dim)\n",
        "        embedded_summed=torch.sum(embedded,dim=1)\n",
        "\n",
        "        #2) apply non-linearity\n",
        "        # (batch,embedding_dim) -> (batch,embedding_dim)\n",
        "        ###projected=torch.tanh(embedded_summed) #Note how non-linearity is applied here and not when configuring the layer in __init__()\n",
        "\n",
        "        #3) and now apply the upper, output layer of the network\n",
        "        # (batch,embedding_dim) -> (batch, num_of_classes i.e. 2 in our case)\n",
        "        logits=self.output(embedded_summed)\n",
        "\n",
        "        # ...and that's all there is to it!\n",
        "\n",
        "        #print(\"input_ids.shape\",input_ids.shape)\n",
        "        #print(\"embedded.shape\",embedded.shape)\n",
        "        #print(\"embedded_summed.shape\",embedded_summed.shape)\n",
        "        #print(\"projected.shape\",projected.shape)\n",
        "        #print(\"logits.shape\",logits.shape)\n",
        "\n",
        "        # If we have labels, we ought to calculate the loss\n",
        "        if labels is not None:\n",
        "            loss=torch.nn.CrossEntropyLoss() #This loss is meant for classification, so let's use it\n",
        "            # You run it as loss(model_output,correct_labels)\n",
        "            return (loss(logits,labels),logits)\n",
        "        else:\n",
        "            # No labels, so just return the logits\n",
        "            return (logits,)\n",
        "\n"
      ],
      "metadata": {
        "id": "vP4FtrMwCpGi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the model:\n",
        "#   these parameters are used in the model's __init__()\n",
        "mlp_config=MLPConfig(vocab_size=len(vectorizer.vocabulary_),hidden_size=1,nlabels=2) # <---- CHANGED 20 -> 1\n",
        "\n",
        "# And now we can instantiate it\n",
        "mlp=MLP(mlp_config)\n",
        "\n",
        "#we can make a little test with a fake batch formed by the two first example\n",
        "fake_batch=collator([dset_tokenized[\"train\"][0],dset_tokenized[\"train\"][1]])\n",
        "mlp(**fake_batch) #** expands input_ids and labels as parameters of the call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQjSGUYGwrzh",
        "outputId": "234bb7c1-1973-4da9-c071-f8fd4d097a3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7556, grad_fn=<NllLossBackward0>),\n",
              " tensor([[0.0842, 0.2052],\n",
              "         [0.0837, 0.2050]], grad_fn=<AddmmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "\n",
        "We will use the Hugging Face [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) class for training\n",
        "\n",
        "* Loads of arguments that control the training\n",
        "* Configurable metrics to evaluate performance\n",
        "* Data collator builds the batches\n",
        "* Early stopping callback stops when eval loss no longer improves\n",
        "* Model load/save\n",
        "* Excellent foundation for later deep learning course\n",
        "  "
      ],
      "metadata": {
        "id": "tdlcMObzQGGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's create a [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.TrainingArguments) object to specify hyperparameters and various other settings for training.\n",
        "\n",
        "Printing this simple dataclass object will show not only the values we set, but also the defaults for all other arguments. Don't worry if you don't understand what all of these do! Many are not relevant to us here, and you can find the details in [`Trainer` documentation](https://huggingface.co/docs/transformers/main_classes/trainer) if you are interested."
      ],
      "metadata": {
        "id": "aZgcNi4B76SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training arguments\n",
        "# their names are mostly self-explanatory\n",
        "trainer_args = transformers.TrainingArguments(\n",
        "    \"mlp_checkpoints\", #save checkpoints here\n",
        "    evaluation_strategy=\"steps\",\n",
        "    logging_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    logging_steps=500,\n",
        "    learning_rate=1e-5, #learning rate of the gradient descent\n",
        "    max_steps=20000,\n",
        "    load_best_model_at_end=True,\n",
        "    per_device_train_batch_size=128\n",
        ")\n",
        "\n",
        "pprint(trainer_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhfdW62z8cCn",
        "outputId": "07cf22f6-e247-4f34-ae54-4881a2a329b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=mlp_checkpoints/runs/Mar30_08-54-23_304885d1877c,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=20000,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=mlp_checkpoints,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=128,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=mlp_checkpoints,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's create a metric for evaluating performance during and after training. We can use the convenience function [`load_metric`](https://huggingface.co/docs/datasets/about_metrics) to load one of many pre-made metrics and wrap this for use by the trainer.\n",
        "\n",
        "As the task is simple binary classification and our data is even 50:50 balanced, we can comfortably use the basic `accuracy` metric, defined as the proportion of correctly predicted labels out of all labels."
      ],
      "metadata": {
        "id": "4sJwNXPU-dQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_accuracy(outputs_and_labels):\n",
        "    outputs, labels = outputs_and_labels\n",
        "    predictions = np.argmax(outputs, axis=-1) #pick the index of the \"winning\" label\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "u3jxIItb0BL9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then create the `Trainer` and train the model by invoking the [`Trainer.train`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.train) function.\n",
        "\n",
        "In addition to the model, the settings passed in through the `TrainingArguments` object created above (`trainer_args`), the data, and the metric defined above, we create and pass the following to the `Trainer`:\n",
        "\n",
        "* [data collator](https://huggingface.co/docs/transformers/main_classes/data_collator): groups input into batches\n",
        "* [`EarlyStoppingCallback`](https://huggingface.co/docs/transformers/main_classes/callback#transformers.EarlyStoppingCallback): stops training when performance stops improving"
      ],
      "metadata": {
        "id": "S7kbz8uU-zpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a new model\n",
        "mlp = MLP(mlp_config)\n",
        "\n",
        "\n",
        "# Argument gives the number of steps of patience before early stopping\n",
        "# i.e. training is stopped when the evaluation loss fails to improve\n",
        "# certain number of times\n",
        "early_stopping = transformers.EarlyStoppingCallback(5)\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=mlp,\n",
        "    args=trainer_args,\n",
        "    train_dataset=dset_tokenized[\"train\"],\n",
        "    eval_dataset=dset_tokenized[\"test\"].select(range(1000)), #make a smaller subset to evaluate on\n",
        "    compute_metrics=compute_accuracy,\n",
        "    data_collator=collator,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# FINALLY!\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "AoEoWsj4P_zN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c17de59-f959-4776-9962-1a82791c2a06"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20000/20000 06:19, Epoch 102/103]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.721700</td>\n",
              "      <td>0.709292</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.691000</td>\n",
              "      <td>0.686313</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.673500</td>\n",
              "      <td>0.671380</td>\n",
              "      <td>0.556000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.659300</td>\n",
              "      <td>0.658895</td>\n",
              "      <td>0.578000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.646100</td>\n",
              "      <td>0.647534</td>\n",
              "      <td>0.607000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.633400</td>\n",
              "      <td>0.636959</td>\n",
              "      <td>0.639000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.621700</td>\n",
              "      <td>0.626799</td>\n",
              "      <td>0.669000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.610500</td>\n",
              "      <td>0.617273</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.599600</td>\n",
              "      <td>0.608289</td>\n",
              "      <td>0.697000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.589400</td>\n",
              "      <td>0.599811</td>\n",
              "      <td>0.716000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.580100</td>\n",
              "      <td>0.591744</td>\n",
              "      <td>0.732000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.570700</td>\n",
              "      <td>0.584095</td>\n",
              "      <td>0.745000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.562700</td>\n",
              "      <td>0.577119</td>\n",
              "      <td>0.754000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.554600</td>\n",
              "      <td>0.570416</td>\n",
              "      <td>0.767000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.564068</td>\n",
              "      <td>0.776000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.539700</td>\n",
              "      <td>0.558167</td>\n",
              "      <td>0.783000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.533300</td>\n",
              "      <td>0.552539</td>\n",
              "      <td>0.788000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.547298</td>\n",
              "      <td>0.798000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.521300</td>\n",
              "      <td>0.542408</td>\n",
              "      <td>0.804000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.515800</td>\n",
              "      <td>0.537840</td>\n",
              "      <td>0.809000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.511200</td>\n",
              "      <td>0.533555</td>\n",
              "      <td>0.813000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.505900</td>\n",
              "      <td>0.529534</td>\n",
              "      <td>0.817000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.501500</td>\n",
              "      <td>0.525807</td>\n",
              "      <td>0.816000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.497100</td>\n",
              "      <td>0.522344</td>\n",
              "      <td>0.821000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.493400</td>\n",
              "      <td>0.519156</td>\n",
              "      <td>0.824000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.490200</td>\n",
              "      <td>0.516176</td>\n",
              "      <td>0.826000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.487100</td>\n",
              "      <td>0.513422</td>\n",
              "      <td>0.829000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.483800</td>\n",
              "      <td>0.510935</td>\n",
              "      <td>0.831000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.481000</td>\n",
              "      <td>0.508668</td>\n",
              "      <td>0.832000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.478800</td>\n",
              "      <td>0.506584</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.476300</td>\n",
              "      <td>0.504785</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.474200</td>\n",
              "      <td>0.503145</td>\n",
              "      <td>0.832000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.472800</td>\n",
              "      <td>0.501722</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.470500</td>\n",
              "      <td>0.500481</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.470400</td>\n",
              "      <td>0.499458</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.468700</td>\n",
              "      <td>0.498616</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.467400</td>\n",
              "      <td>0.497941</td>\n",
              "      <td>0.834000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.467400</td>\n",
              "      <td>0.497482</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.466700</td>\n",
              "      <td>0.497203</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.466600</td>\n",
              "      <td>0.497111</td>\n",
              "      <td>0.833000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory mlp_checkpoints/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-6000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-6500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-7000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-7500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-8000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-8500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-9000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-9500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-10000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-10500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-11000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-11500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-12000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-12500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-13000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-13500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-14000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-14500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-15000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-15500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-16000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-16500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-17000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-17500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-18000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-18500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-19000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-19500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory mlp_checkpoints/checkpoint-20000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=20000, training_loss=0.5382539276123047, metrics={'train_runtime': 380.621, 'train_samples_per_second': 6725.85, 'train_steps_per_second': 52.546, 'total_flos': 26142040896.0, 'train_loss': 0.5382539276123047, 'epoch': 102.04})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then evaluate the trained model on a given dataset (here our test subset) by calling [`Trainer.evaluate`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.evaluate):"
      ],
      "metadata": {
        "id": "Td03fcIa-6Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate(dset_tokenized[\"test\"])\n",
        "\n",
        "print(eval_results)"
      ],
      "metadata": {
        "id": "9nlEwpnF2Vow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f9076004-4da6-475c-e8a0-c41625e5fd36"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.49380069971084595, 'eval_accuracy': 0.8356, 'eval_runtime': 7.786, 'eval_samples_per_second': 3210.885, 'eval_steps_per_second': 401.361, 'epoch': 102.04}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model for later use\n",
        "\n",
        "* You can save it with `trainer.save_model()`\n",
        "* You can load it with `MLP.from_pretrained()`\n"
      ],
      "metadata": {
        "id": "P0OYB3TRp-IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"mlp-imdb\")"
      ],
      "metadata": {
        "id": "FosHTDw3p9dd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check save/load"
      ],
      "metadata": {
        "id": "8D8W9EN-zMAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp2=MLP.from_pretrained(\"mlp-imdb\")"
      ],
      "metadata": {
        "id": "UKMMNbABqLTg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=mlp2,\n",
        "    args=trainer_args,\n",
        "    train_dataset=dset_tokenized[\"train\"],\n",
        "    eval_dataset=dset_tokenized[\"test\"],\n",
        "    compute_metrics=compute_accuracy,\n",
        "    data_collator=collator,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "pfLnUENrrCyp",
        "outputId": "cdbed78a-51c5-4381-f032-602423fe97ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate(dset_tokenized[\"test\"])\n",
        "print(eval_results)\n",
        "print('Accuracy:', eval_results['eval_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "hpOM2ZwErMGf",
        "outputId": "4ddb8b5e-0c74-473f-ebec-715fe898e5b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.49380069971084595, 'eval_accuracy': 0.8356, 'eval_runtime': 7.5327, 'eval_samples_per_second': 3318.865, 'eval_steps_per_second': 414.858}\n",
            "Accuracy: 0.8356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra time left?\n",
        "\n",
        "* Read through the TrainingArguments documentation, try to understand at least some parts of it https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n",
        "* Read through Torch tensor operations, try to understand at least some parts of it: https://pytorch.org/docs/stable/tensors.html\n",
        "* Run the model with different parameters (hidden layer width, learning rate, etc), how much do the results change?\n"
      ],
      "metadata": {
        "id": "8UT5MV1LtSBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What has the model learned?\n",
        "\n",
        "* The embeddings should have some meaning to them\n",
        "* Similar features should have similar embeddings"
      ],
      "metadata": {
        "id": "13aB7DuqzeFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the embedding matrix out of the trained model\n",
        "# and drop the first row (padding 0)\n",
        "# then we can treat the embeddings as vectors\n",
        "# and maybe compare them to each other\n",
        "# ha ha this below took some googling\n",
        "weights=mlp.embedding.weight.detach().cpu().numpy()\n",
        "weights=weights[1:,:]\n"
      ],
      "metadata": {
        "id": "M6TUrVkMCmz7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qry_idx=vectorizer.vocabulary_[\"great\"] #embedding of \"great\"\n",
        "\n",
        "#calculate the distance of the \"lousy\" embedding to all other embeddings\n",
        "distance_to_qry=sklearn.metrics.pairwise.euclidean_distances(weights[qry_idx:qry_idx+1,:],weights)\n",
        "nearest_neighbors=np.argsort(distance_to_qry) #indices of words nearest to \"lousy\"\n",
        "for nearest in nearest_neighbors[0,:20]:\n",
        "    print(idx2word[nearest])\n",
        "# This works great!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uTTvRgGDU9D",
        "outputId": "58e6aca7-db10-4421-87e2-083d006d4cdb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "great\n",
            "excellent\n",
            "wonderful\n",
            "amazing\n",
            "perfect\n",
            "best\n",
            "loved\n",
            "favorite\n",
            "superb\n",
            "love\n",
            "beautiful\n",
            "fantastic\n",
            "highly\n",
            "enjoyed\n",
            "brilliant\n",
            "today\n",
            "beautifully\n",
            "wonderfully\n",
            "touching\n",
            "gem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The embeddings indeed seem to reflect the task\n",
        "* There is a meaning to them"
      ],
      "metadata": {
        "id": "cQCmThdu2LDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature weights\n",
        "\n",
        "*   A typical \"old-school\" way to approach the classification would be a simple linear model, like LinearSVM\n",
        "*   Under such model, each feature (word) would have a single one weight\n",
        "*   And the classification would simply be based on the sum of these weights\n",
        "*   In this context of this task, \"positive\" words would get a high weight, \"negative\" words would get a low weight\n",
        "*   It is in fact quite easy to reconfigure the MLP model to work more or less like this and this effect can be replicated\n",
        "*   I will leave that as an exercise for you\n",
        "\n"
      ],
      "metadata": {
        "id": "Jydy3ECK3O2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRINT PART\n",
        "\n",
        "sorted = weights.flatten().argsort()\n",
        "\n",
        "print(\"POS\", \"v\"*27)\n",
        "for i in sorted[-30:]: # POS\n",
        "  print(idx2word[i])\n",
        "print(\"POS\", \"^\"*27)\n",
        "\n",
        "print(\"NEG\", \"v\"*27)\n",
        "for i in sorted[:30]: # POS\n",
        "  print(idx2word[i])\n",
        "print(\"NEG\", \"^\"*27)\n"
      ],
      "metadata": {
        "id": "bU-ZB3iMdPe7",
        "outputId": "baffa754-e646-458f-a212-1c8b40c0f3ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS vvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
            "perfectly\n",
            "outstanding\n",
            "very\n",
            "always\n",
            "also\n",
            "fun\n",
            "recommended\n",
            "heart\n",
            "well\n",
            "definitely\n",
            "gem\n",
            "touching\n",
            "wonderfully\n",
            "beautifully\n",
            "today\n",
            "brilliant\n",
            "enjoyed\n",
            "highly\n",
            "fantastic\n",
            "beautiful\n",
            "love\n",
            "superb\n",
            "favorite\n",
            "loved\n",
            "best\n",
            "perfect\n",
            "amazing\n",
            "wonderful\n",
            "excellent\n",
            "great\n",
            "POS ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "NEG vvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
            "worst\n",
            "bad\n",
            "waste\n",
            "awful\n",
            "terrible\n",
            "worse\n",
            "boring\n",
            "poor\n",
            "stupid\n",
            "poorly\n",
            "horrible\n",
            "supposed\n",
            "crap\n",
            "nothing\n",
            "pointless\n",
            "lame\n",
            "minutes\n",
            "ridiculous\n",
            "dull\n",
            "avoid\n",
            "mess\n",
            "badly\n",
            "annoying\n",
            "wasted\n",
            "laughable\n",
            "money\n",
            "script\n",
            "pathetic\n",
            "no\n",
            "redeeming\n",
            "NEG ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        }
      ]
    }
  ]
}