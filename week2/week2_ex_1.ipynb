{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python function that takes a dataset name as an argument, loads the dataset, and calculates and prints out the following information about the dataset:\n",
        "\n",
        "    The description of the dataset (use load_dataset_builder)\n",
        "    Relative sizes of the subsets of the dataset (e.g. 'train', 'validation', and 'test') in terms of examples (rows). For example: \"train: 50%, validation: 25%, test: 25%\"\n",
        "    Distribution of labels in the 'train' subset of the dataset, using the names of the labels. For example: \"positive: 53%, negative: 47%\"\n",
        "\n",
        "(You can assume that the function will only be called with the names of datasets representing text classification corpora.)\n",
        "\n",
        "Apply this function to the following datasets: 'emotion', 'rotten_tomatoes', 'snli', 'sst2', 'emo'.\n",
        "\n",
        "What patterns can you notice in the relative sizes of the subsets? Can you tell why this might be?"
      ],
      "metadata": {
        "id": "ed5FsUjqCsu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Zlg7lBbuDQlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtXqnPyRCnF6",
        "outputId": "83fb28b9-f47f-48bd-dfde-6baf3368d609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n",
            "\n",
            "{'train': 16000, 'validation': 2000, 'test': 2000}\n",
            "train: 80% \tvalidation: 10% \ttest: 10% \t\n",
            "{'sadness': 0, 'joy': 0, 'love': 0, 'anger': 0, 'fear': 0, 'surprise': 0}\n",
            "No description found for dataset rotten_tomatoes\n",
            "{'train': 8530, 'validation': 1066, 'test': 1066}\n",
            "train: 80% \tvalidation: 10% \ttest: 10% \t\n",
            "{'neg': 0, 'pos': 0}\n",
            "No description found for dataset snli\n",
            "{'test': 10000, 'validation': 10000, 'train': 550152}\n",
            "test: 2% \tvalidation: 2% \ttrain: 96% \t\n",
            "{'entailment': 0, 'neutral': 0, 'contradiction': 0}\n",
            "No description found for dataset sst2\n",
            "{'train': 67349, 'validation': 872, 'test': 1821}\n",
            "train: 96% \tvalidation: 1% \ttest: 3% \t\n",
            "{'negative': 0, 'positive': 0}\n",
            "In this dataset, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others.\n",
            "\n",
            "{'train': 30160, 'test': 5509}\n",
            "train: 85% \ttest: 15% \t\n",
            "{'others': 0, 'happy': 0, 'sad': 0, 'angry': 0}\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "datasets.disable_progress_bar()\n",
        "\n",
        "def extractor(x):\n",
        "\n",
        "  # The description of the dataset (use load_dataset_builder)\n",
        "  ds_builder = load_dataset_builder(x, trust_remote_code=True)\n",
        "  description = ds_builder.info.description\n",
        "  if len(description) == 0:\n",
        "    print(f'No description found for dataset {x}')\n",
        "  else:\n",
        "    print(description)\n",
        "\n",
        "\n",
        "  # Relative sizes of the subsets of the dataset\n",
        "  dataset = load_dataset(x, trust_remote_code=True)\n",
        "  print(dataset.num_rows)\n",
        "\n",
        "  subsets = dict(dataset.num_rows)\n",
        "  allrows = sum(subsets.values())\n",
        "  st = \"\"\n",
        "  for k,v in subsets.items():\n",
        "    st += f'{k}: {round((v * 100) / allrows)}% \\t'\n",
        "  print(st)\n",
        "\n",
        "  #Distribution of labels in the 'train' subset of the dataset, using the names of the labels. For example: \"positive: 53%, negative: 47%\"\n",
        "  only_train = load_dataset(x, split = 'train', trust_remote_code=True)\n",
        "  label_names = dict.fromkeys(only_train.features['label'].names, 0)\n",
        "  print(label_names)\n",
        "\n",
        "DATASETS = ['emotion', 'rotten_tomatoes', 'snli', 'sst2', 'emo']\n",
        "\n",
        "for x in DATASETS:\n",
        "  extractor(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What patterns can you notice in the relative sizes of the subsets? Can you tell why this might be?"
      ],
      "metadata": {
        "id": "Aa4u763vSbs1"
      }
    }
  ]
}