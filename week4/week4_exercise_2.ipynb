{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUf4c/mr0lsa5wAQY1lyif",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heinohen/tko_7095_i2hlt/blob/main/week4_exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 8: POS transition probabilities\n",
        "\n",
        "In the lecture, we briefly saw the concept of hidden markov models and transition probabilies, as applied to POS tags. In the simplest case, these probabilities model the sequences of POS tag pairs such that e.g. probability of DET -> NOUN will be the probability of seeing a NOUN, having seen a DET (determiner), i.e. more formally the conditional probability P(NOUN|DET). We also had the intuition that for example DET -> NOUN should be much larger than, say DET -> VERB. And of course, since these are conditional probabilities, sum of P(x|y) over all x should sum up to 1 for any given y. These probabilities can be easily estimated by counting from the data, i.e. the probability of DET -> NOUN transition, i.e. P(NOUN|DET) is simply the count of how many times you saw NOUN following a DET, divided by how many times you saw DET.\n",
        "\n",
        "Your task is to pick a Universal Dependencies dataset of your choice, e.g. UD_English-EWT training data, calculate these transition probabilities, pretty-print them if you can, and check that our intuitions hold, i.e. that for example DET -> NOUN is substantially more likely than, say, DET -> VERB."
      ],
      "metadata": {
        "id": "Tq2Rmh7t6acI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data"
      ],
      "metadata": {
        "id": "SY5szSsB_sut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to pick a Universal Dependencies dataset of your choice, e.g. UD_English-EWT training data,\n",
        "\n"
      ],
      "metadata": {
        "id": "Wv2AsHxl6TOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description\n",
        "\n",
        "A Gold Standard Universal Dependencies Corpus for English, built over the source material of the English Web Treebank LDC2012T13 (https://catalog.ldc.upenn.edu/LDC2012T13).\n"
      ],
      "metadata": {
        "id": "6-d4AWtz6QSf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsS3vdkq54xZ"
      },
      "outputs": [],
      "source": [
        "!wget -nc --quiet https://github.com/UniversalDependencies/UD_English-EWT/raw/master/en_ewt-ud-train.conllu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate scores"
      ],
      "metadata": {
        "id": "lbELUCCb7RF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZHqG4z3E_hAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def counts(file_name, target_pos, another_pos, counter_pos) -> list:\n",
        "  with open(file_name) as f:\n",
        "    first_line = True # just to determine if it is or not :)\n",
        "    last_UPOS = \"\"\n",
        "    # probability of DET -> NOUN will be the probability of seeing a NOUN, having seen a DET (determiner),\n",
        "    # i.e. more formally the conditional probability P(NOUN|DET).\n",
        "    noun_after_det = 0\n",
        "    # Just DET\n",
        "    just_det = 0\n",
        "    # DET -> VERB\n",
        "    verb_after_det = 0\n",
        "    # ALL\n",
        "    all_words = 0\n",
        "    for line in f:\n",
        "      line = line.rstrip('\\n')\n",
        "\n",
        "      if first_line or line.startswith('#') or not line:\n",
        "        first_line = False\n",
        "        continue\n",
        "      all_words += 1\n",
        "      # expect datalines\n",
        "      cols = line.split('\\t')\n",
        "      ID, FORM, LEMMA, UPOS, XPOS, FEATS, HEAD, DEPREL, DEPS, MISC = cols\n",
        "\n",
        "      # if case is that current is NOUN and last seen was DET\n",
        "      if UPOS == target_pos and last_UPOS == another_pos:\n",
        "        noun_after_det += 1\n",
        "        first_line = False\n",
        "\n",
        "      # if case is that current is VERB and last seen was DET\n",
        "      elif UPOS == counter_pos and last_UPOS == another_pos:\n",
        "        verb_after_det += 1\n",
        "        last_UPOS = UPOS\n",
        "        first_line = False\n",
        "\n",
        "      # if current is DET\n",
        "      elif UPOS == another_pos:\n",
        "        just_det += 1\n",
        "        last_UPOS = UPOS\n",
        "        first_line = False\n",
        "\n",
        "      # if not, update the last UPOS with current\n",
        "      else:\n",
        "        last_UPOS = UPOS\n",
        "        first_line = False\n",
        "\n",
        "  return [noun_after_det,just_det, verb_after_det, all_words]\n",
        "\n",
        "\n",
        "\n",
        "file_name = \"en_ewt-ud-train.conllu\"\n",
        "count_list = counts(file_name, \"NOUN\", \"DET\", \"VERB\")\n",
        "count_list\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPrxav1_7OT4",
        "outputId": "2474aae3-08ac-4c6d-8aae-c0374fd83336"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10920, 16299, 962, 207227]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Prints"
      ],
      "metadata": {
        "id": "Nuh8T4Q6_z6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " calculate these transition probabilities, pretty-print them if you can, and check that our intuitions hold, i.e. that for example DET -> NOUN is substantially more likely than, say, DET -> VERB.\n",
        "\n",
        " the probability of DET -> NOUN transition, i.e. P(NOUN|DET) is simply the count of how many times you saw NOUN following a DET, divided by how many times you saw DET."
      ],
      "metadata": {
        "id": "1zLwteNl_kRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tabulate\n",
        "\n",
        "det_noun_trans = count_list[0] / count_list[1]\n",
        "det_verb_trans = count_list[2] / count_list[1]\n",
        "det_alone = count_list[1] / count_list[3]\n",
        "\n",
        "data = [\n",
        "    [\"DET NOUN transfer\", det_noun_trans],\n",
        "    [\"DET VERB transfer\", det_verb_trans],\n",
        "    [\"DET alone\", det_alone]\n",
        "]\n",
        "\n",
        "print(tabulate.tabulate(data, headers=[\"Case: \", \"(Conditional) probability\"]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYtQbr88_3Jz",
        "outputId": "917d77a3-d323-4cf7-b80f-ec99dec6f087"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case:                (Conditional) probability\n",
            "-----------------  ---------------------------\n",
            "DET NOUN transfer                    0.66998\n",
            "DET VERB transfer                    0.059022\n",
            "DET alone                            0.0786529\n"
          ]
        }
      ]
    }
  ]
}